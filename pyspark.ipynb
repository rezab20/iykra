{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- membuat ETL menggunakan spark ke database postgreSQL\n",
    "- database yang digunakan adalah database movie rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql import functions as fnc\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating spark session : 0.010308980941772461 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "POSTGRESQL_JDBC_PATH = \"postgresql-42.2.19.jar\"\n",
    "spark = SparkSession.builder.appName(\"Pyspark_film\").config(\"spark.jars\", POSTGRESQL_JDBC_PATH).getOrCreate()\n",
    "print(f\"Creating spark session : {time.time() - now_} s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingSchema = StructType([ \\\n",
    "    StructField(\"userID\", IntegerType(), True), \\\n",
    "    StructField(\"movieID\", IntegerType(), True), \\\n",
    "    StructField(\"rating\", IntegerType(), True), \\\n",
    "    StructField(\"time\", IntegerType(), True)]\n",
    ")\n",
    "\n",
    "moviesSchema = StructType([ \\\n",
    "    StructField(\"movieID\", IntegerType(), True), \\\n",
    "    StructField(\"movieTitle\", StringType(), True), \\\n",
    "    StructField(\"genres\", StringType(), True)]\n",
    ")\n",
    "\n",
    "def getRatingPercent(rating):\n",
    "    return rating/5 * 100\n",
    "getRatingPercentUDF = fnc.udf(getRatingPercent)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ratings: 0.12536382675170898 s\n",
      "Ratings data length: 1000209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "ratingsDF = spark.read.option(\"sep\", \"::\").schema(ratingSchema).csv(\"ml-1m/ratings.dat\")\n",
    "print(f\"Loading data ratings: {time.time() - now_} s\")\n",
    "print(f\"Ratings data length: {ratingsDF.count()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data films: 0.025614023208618164 s\n",
      "Films data length: 3883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_= time.time()\n",
    "moviesDF = spark.read.option(\"sep\", \"::\").schema(moviesSchema).csv(\"ml-1m/movies.dat\")\n",
    "print(f\"Loading data films: {time.time() - now_} s\")\n",
    "print(f\"Films data length: {moviesDF.count()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create rating percentage: 0.06072711944580078 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "ratingsDF = ratingsDF.withColumn(\"ratingPercent\", getRatingPercentUDF(fnc.col(\"rating\")).cast(IntegerType()))\n",
    "print(f\"Create rating percentage: {time.time() - now_} s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining ratings and films dataframes: 0.06629085540771484 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "ratingsDF = ratingsDF.alias('ratings')\n",
    "moviesDF = moviesDF.alias('movies')\n",
    "joinedDF = ratingsDF.join(moviesDF, fnc.col('ratings.movieID') == fnc.col('movies.movieID')) \\\n",
    "            .select('ratings.*', 'movies.movieTitle', 'movies.genres')\n",
    "print(f\"Joining ratings and films dataframes: {time.time() - now_} s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create average rating for each movieID dataframe: 0.05833721160888672 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "ratingsAvgDF = ratingsDF[\"movieID\",\"ratingPercent\"].groupBy(\"movieID\").avg()\n",
    "print(f\"Create average rating for each movieID dataframe: {time.time() - now_} s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joined dataframe to postgresql: 16.260953903198242 s\n",
      "\n",
      "Total time: 42.30452036857605 s\n",
      "\n",
      "Stopping Spark session ...\n",
      "Spark session stopped\n"
     ]
    }
   ],
   "source": [
    "now_ = time.time()\n",
    "joinedDF.repartition(10) \\\n",
    "    .write.format('jdbc').options(\n",
    "        url='jdbc:postgresql://localhost:5433/spark_try',\n",
    "        driver='org.postgresql.Driver',\n",
    "        dbtable='film_rating_spark',\n",
    "        user='postgres',\n",
    "        password='admin'\n",
    "    ).save()\n",
    "print(f\"Writing joined dataframe to postgresql: {time.time() - now_} s\\n\")\n",
    "\n",
    "print(f\"Total time: {time.time() - start_time} s\\n\")\n",
    "\n",
    "print(\"Stopping Spark session ...\")\n",
    "spark.stop()\n",
    "print(\"Spark session stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "berdasarkan hasil percobaan diperoleh waktu eksekusi selama 42.30452036857605 detik, \n",
    "untuk membuat ETL dengan spark "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
